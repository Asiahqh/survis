{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaIkB3hOtNpZbvYC09B/7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asiahqh/survis/blob/master/Copy_of_Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K7xSE0bFJPu",
        "outputId": "7aa03287-3851-4e9e-aa24-b426defd929e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating bibliography data...\n",
            "Update completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import codecs\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the paths using the correct location of the files in Colab\n",
        "BASE_DIR = Path('/content')\n",
        "\n",
        "DATA_DIR = BASE_DIR / \"data\"\n",
        "PAPERS_DIR = DATA_DIR / \"papers_pdf\"\n",
        "PAPERS_IMG_DIR = DATA_DIR / \"papers_img\"\n",
        "BIB_FILE = BASE_DIR / \"references.bib\"  # Updated path\n",
        "GENERATED_DIR = DATA_DIR / \"generated\"\n",
        "BIB_JS_FILE = GENERATED_DIR / \"bib.js\"\n",
        "AVAILABLE_PDF_FILE = GENERATED_DIR / \"available_pdf.js\"\n",
        "AVAILABLE_IMG_FILE = GENERATED_DIR / \"available_img.js\"\n",
        "\n",
        "# Ensure the directories exist\n",
        "def generate_folders():\n",
        "    for directory in [DATA_DIR, PAPERS_DIR, PAPERS_IMG_DIR, GENERATED_DIR]:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Parse the .bib file\n",
        "def parse_bibtex(bib_file):\n",
        "    parsed_data = {}\n",
        "    try:\n",
        "        with bib_file.open(\"r\", encoding=\"utf-8-sig\") as file:\n",
        "            current_id = \"\"\n",
        "            for line in file:\n",
        "                line = line.strip()\n",
        "                if line.startswith(\"@Comment\"):\n",
        "                    continue\n",
        "                if line.startswith(\"@\"):\n",
        "                    current_id = line.split(\"{\")[1].rstrip(\",\\n\")\n",
        "                    current_type = line.split(\"{\")[0].strip(\"@ \")\n",
        "                    parsed_data[current_id] = {\"type\": current_type}\n",
        "                elif \"=\" in line and current_id:\n",
        "                    field, value = line.split(\"=\", 1)\n",
        "                    field = field.strip().lower()\n",
        "                    value = value.strip(\"{} \\n,\").strip()\n",
        "                    parsed_data[current_id][field] = value\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {bib_file} does not exist.\")\n",
        "    return parsed_data\n",
        "\n",
        "# Write parsed data to JSON\n",
        "def write_json(parsed_data, output_file):\n",
        "    try:\n",
        "        with output_file.open(\"w\", encoding=\"utf-8-sig\") as f:\n",
        "            f.write(\"const generatedBibEntries = \")\n",
        "            f.write(json.dumps(parsed_data, sort_keys=True, indent=4, separators=(',', ': ')))\n",
        "            f.write(\";\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error writing to {output_file}: {e}\")\n",
        "\n",
        "# Main update function\n",
        "def update():\n",
        "    print(\"Updating bibliography data...\")\n",
        "    write_json(parse_bibtex(BIB_FILE), BIB_JS_FILE)\n",
        "    print(\"Update completed.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    generate_folders()\n",
        "    update()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/data/generated/bib.js\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siqy7XRpFooT",
        "outputId": "ed9eb326-7be5-483f-b08d-1609aa24c392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿const generatedBibEntries = {\n",
            "    \"Beck2016Visual\": {\n",
            "        \"abstract\": \"Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.\",\n",
            "        \"author\": \"Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel\",\n",
            "        \"doi\": \"10.1109/TVCG.2015.2467757\",\n",
            "        \"journal\": \"IEEE Transactions on Visualization and Computer Graphics\",\n",
            "        \"keywords\": \"type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser\",\n",
            "        \"number\": \"01\",\n",
            "        \"publisher\": \"IEEE\",\n",
            "        \"series\": \"TVCG\",\n",
            "        \"title\": \"Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis\",\n",
            "        \"type\": \"article\",\n",
            "        \"url\": \"http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf\",\n",
            "        \"volume\": \"22\",\n",
            "        \"year\": \"2016\"\n",
            "    }\n",
            "};"
          ]
        }
      ]
    }
  ]
}